{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nUsing Language Models\\n1. Assumption for Naive Bayes : All words are independent\\nslide no 38.\\n2. Naive Bayes is a probabilistic classifier.\\n3. We compute the probability of document being in class C.\\n4. The goal of the naive bayes class is to find the best class.\\n5. Naive Bayes = probability of each class + prob of each token belonging to that class.\\n'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Using Language Models\n",
    "1. Assumption for Naive Bayes : All words are independent\n",
    "slide no 38.\n",
    "2. Naive Bayes is a probabilistic classifier.\n",
    "3. We compute the probability of document being in class C.\n",
    "4. The goal of the naive bayes class is to find the best class.\n",
    "5. Naive Bayes = probability of each class + prob of each token belonging to that class.\n",
    "6. Formula = argmax(log(P(c) + log(P(t/c)))\n",
    "7. Smoothing in NB\n",
    "8. P(t/c) = T(no of particular token) + 1 / T(sum of all tokens in a class) + V(size of vocab)\n",
    "9. Naive bayes is good for predicting the class and not for estimating probabilites.\n",
    "10. Naive Bayes is robust to concept drift. (change of definition of class over time).\n",
    "11. For text, the independence assumption does not hold for naive bayes, but for other domains it does hold.\n",
    "12. Advantages:\n",
    "    1. Very Fast\n",
    "    2. Low storage requirement\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ItishaYadav1/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "b'Skipping line 119: expected 2 fields, saw 7\\nSkipping line 1213: expected 2 fields, saw 4\\nSkipping line 2323: expected 2 fields, saw 3\\nSkipping line 2803: expected 2 fields, saw 3\\nSkipping line 3630: expected 2 fields, saw 4\\nSkipping line 4635: expected 2 fields, saw 5\\nSkipping line 4797: expected 2 fields, saw 4\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": "        Y                                                  X\n0     4.0  When I understood that I was admitted to the U...\n1     1.0  I broke a window of a neighbouring house and I...\n2     4.0                         Got a big fish in fishing.\n3     1.0  Whenever I am alone in a dark room, walk alone...\n4     5.0  I bought a possible answer to a homework probl...\n...   ...                                                ...\n5321  7.0  After a disagreement between my parents, when ...\n5322  3.0  One day I shouted at my brother who didn't do ...\n5323  1.0  Before one of my final exams of the third year...\n5324  6.0  A drunk man bumped into me and wanted to grip ...\n5325  5.0  Had a very good friend. We grew apart I found ...\n\n[5326 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Y</th>\n      <th>X</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4.0</td>\n      <td>When I understood that I was admitted to the U...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>I broke a window of a neighbouring house and I...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>Got a big fish in fishing.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>Whenever I am alone in a dark room, walk alone...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>I bought a possible answer to a homework probl...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5321</th>\n      <td>7.0</td>\n      <td>After a disagreement between my parents, when ...</td>\n    </tr>\n    <tr>\n      <th>5322</th>\n      <td>3.0</td>\n      <td>One day I shouted at my brother who didn't do ...</td>\n    </tr>\n    <tr>\n      <th>5323</th>\n      <td>1.0</td>\n      <td>Before one of my final exams of the third year...</td>\n    </tr>\n    <tr>\n      <th>5324</th>\n      <td>6.0</td>\n      <td>A drunk man bumped into me and wanted to grip ...</td>\n    </tr>\n    <tr>\n      <th>5325</th>\n      <td>5.0</td>\n      <td>Had a very good friend. We grew apart I found ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5326 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mapping = {\"fear\": 1, \"anger\": 2, \"guilt\": 3, \"joy\": 4, \"shame\": 5, \"disgust\": 6, \"sadness\": 7}\n",
    "isear_train_df = pd.read_csv(\"./isear/isear-train.csv\", error_bad_lines=False, header=None)\n",
    "mapped_emotions = isear_train_df[0].map(mapping)\n",
    "isear_train_df[0] = mapped_emotions\n",
    "isear_train_df = isear_train_df.dropna().reset_index(drop=True)\n",
    "isear_train_df = isear_train_df.rename(columns={0: \"Y\", 1: \"X\"})\n",
    "#isear_train_df = isear_train_df[isear_train_df[\"Y\"].isin([4, 7])]\n",
    "isear_train_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.vocabSize = 0\n",
    "        self.trainingSize = 0\n",
    "        self.vocab = []\n",
    "        self.fear = {}\n",
    "        self.anger = {}\n",
    "        self.guilt = {}\n",
    "        self.joy = {}\n",
    "        self.shame = {}\n",
    "        self.disgust = {}\n",
    "        self.sadness = {}\n",
    "        self.fearSize = 0\n",
    "        self.angerSize = 0\n",
    "        self.guiltSize = 0\n",
    "        self.joySize = 0\n",
    "        self.shameSize = 0\n",
    "        self.disgustSize = 0\n",
    "        self.sadnessSize = 0\n",
    "        self.priorDict = {}\n",
    "        self.stopwords = {'hers', 'below', \"wouldn't\", 'nor', 'for', 'over', \"hasn't\", 'at', 'shouldn', 'only', 'above', 'itself', 'yourselves', 'what', \"don't\", \"it's\", 'which', 'against', \"that'll\", 'has', 'i', 'his', 'having', 'then', \"shan't\", 'myself', 'do', 'yours', 'up', 'own', 'the', 'same', 'aren', 'few', 'through', 'here', 'whom', 'o', \"aren't\", 'were', 'are', 'both', \"didn't\", 'll', 'again', 'is', 're', \"wasn't\", \"you'll\", 'm', \"haven't\", 'such', 'off', 'of', 'it', 'did', 'into', 'to', 'other', 'was', 'just', 've', \"mustn't\", 'while', 'about', 'each', 'by', 'this', 'isn', 'ourselves', 'in', 'our', 'couldn', 'until', 'where', \"couldn't\", 'ain', \"you'd\", 'all', 'when', 'does', 'before', 'weren', 'y', 'doing', 'than', 'being', 'my', 'mightn', 'yourself', 'with', 'theirs', 'so', \"needn't\", 'a', \"doesn't\", \"isn't\", 'its', 'your', 'if', \"should've\", 'ma', 'can', 'herself', 'but', 'too', 'more', 'her', \"hadn't\", 'hadn', 'there', \"you're\", 'from', 'should', 'we', 'how', 'out', 'once', 'mustn', 'won', 'their', 'don', 'had', 'he', 'or', 'didn', 'd', 'down', 't', \"she's\", 'that', 'himself', 'wouldn', \"you've\", \"mightn't\", 'between', 'them', 'on', 'haven', 'after', 'themselves', 'because', 'and', 'you', 'very', 's', 'these', 'no', 'now', 'him', 'been', 'those', 'during', 'doesn', 'wasn', 'am', 'under', 'an', 'some', 'have', 'me', 'any', 'who', 'shan', 'why', 'will', \"shouldn't\", 'not', 'they', \"won't\", 'needn', 'further', 'most', 'be', 'ours', 'she', 'as', 'hasn', \"weren't\", \"a\", \"''\"}\n",
    "\n",
    "        self.classMapping = {1: \"fear\", 2: \"anger\", 3: \"guilt\", 4: \"joy\", 5: \"shame\", 6: \"disgust\", 7: \"sadness\"}\n",
    "\n",
    "    def getVocabulary(self, text):\n",
    "        tokens = [re.sub(\"[^A-Za-z]\", \"\",i).strip().lower() for i in text.split(\" \") if i not in self.stopwords and len(i) > 1]\n",
    "        return list(set(tokens))\n",
    "\n",
    "\n",
    "    def updateProbabilityDict(self, emodf, resDict):\n",
    "        text = \" \".join(list(emodf[\"X\"])).split(\" \")\n",
    "        for word in text:\n",
    "            word = re.sub(\"[^A-Za-z]\", \"\", word).strip().lower()\n",
    "            if word not in self.stopwords and len(word) > 1:\n",
    "                if word in resDict:\n",
    "                    resDict[word] += 1\n",
    "                else:\n",
    "                    resDict[word] = 1\n",
    "        size = sum([value for key, value in resDict.items()])\n",
    "        return resDict, size\n",
    "\n",
    "\n",
    "    def maximum_likelihood_estimation(self, instance, emoDict, emotionCorpusSize, emotion):\n",
    "        \"\"\"\n",
    "        instanceDict = {}\n",
    "        for word in instance.split(\" \"):\n",
    "            word = re.sub(\"[^A-Za-z]\", \"\", word).strip().lower()\n",
    "            if word not in self.stopwords and len(word) > 1:\n",
    "                if word in instanceDict:\n",
    "                    instanceDict[word] += 1\n",
    "                else:\n",
    "                    instanceDict[word] = 1\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        p_tc = 0\n",
    "        tokens = [re.sub(\"[^A-Za-z]\", \"\",i).strip().lower() for i in instance.split(\" \") if i not in self.stopwords and len(i) > 1]\n",
    "        for word in tokens:\n",
    "            if word in emoDict:\n",
    "                p_tc += (emoDict[word] + 1) / (emotionCorpusSize + self.vocabSize)\n",
    "            else:\n",
    "                p_tc += 1 / (emotionCorpusSize + self.vocabSize)\n",
    "        return np.log(self.priorDict[emotion]) + np.log(p_tc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"\n",
    "        tokenDict... : holds the probability of occurence of each word in the class, therefore the length of dict = vocab size.\n",
    "        priorDict: holds the probability of occurence of each class\n",
    "        \"\"\"\n",
    "        self.vocab = self.getVocabulary(\" \".join(list(train_df[\"X\"])))\n",
    "        self.vocabSize = len(self.vocab)\n",
    "        self.trainingSize = train_df.shape[0]\n",
    "        self.priorDict = {\"fear\": train_df[train_df[\"Y\"] == 1].shape[0]/self.trainingSize,\n",
    "                          \"anger\": train_df[train_df[\"Y\"] == 2].shape[0]/self.trainingSize,\n",
    "                           \"guilt\": train_df[train_df[\"Y\"] == 3].shape[0]/self.trainingSize,\n",
    "                           \"joy\": train_df[train_df[\"Y\"] == 4].shape[0]/self.trainingSize,\n",
    "                           \"shame\": train_df[train_df[\"Y\"] == 5].shape[0]/self.trainingSize,\n",
    "                           \"disgust\": train_df[train_df[\"Y\"] == 6].shape[0]/self.trainingSize,\n",
    "                           \"sadness\": train_df[train_df[\"Y\"] == 7].shape[0]/self.trainingSize,\n",
    "                          }\n",
    "        self.fear, self.fearSize = self.updateProbabilityDict(train_df[train_df[\"Y\"] == 1], self.fear)\n",
    "        self.anger, self.angerSize = self.updateProbabilityDict(train_df[train_df[\"Y\"] == 2], self.anger)\n",
    "        self.guilt, self.guiltSize = self.updateProbabilityDict(train_df[train_df[\"Y\"] == 3], self.guilt)\n",
    "        self.joy, self.joySize = self.updateProbabilityDict(train_df[train_df[\"Y\"] == 4], self.joy)\n",
    "        self.shame, self.shameSize = self.updateProbabilityDict(train_df[train_df[\"Y\"] == 5], self.shame)\n",
    "        self.disgust, self.disgustSize = self.updateProbabilityDict(train_df[train_df[\"Y\"] == 6], self.disgust)\n",
    "        self.sadness, self.sadnessSize = self.updateProbabilityDict(train_df[train_df[\"Y\"] == 7], self.sadness)\n",
    "\n",
    "\n",
    "    def predict(self, xtest):\n",
    "        \"\"\"\n",
    "        This method uses the probabilites learned in the fit function and applies the formula to get the correct class for the given instance.\n",
    "        \"\"\"\n",
    "\n",
    "        k = 0\n",
    "        predictions = []\n",
    "        for instance in xtest:\n",
    "            k += 1\n",
    "            #print(k, instance)\n",
    "            prob = []\n",
    "\n",
    "            proba_fear = self.maximum_likelihood_estimation(instance, self.fear, emotionCorpusSize=self.fearSize, emotion=\"fear\")\n",
    "            prob.append(proba_fear)\n",
    "            proba_anger = self.maximum_likelihood_estimation(instance, self.anger, emotionCorpusSize=self.angerSize, emotion=\"anger\")\n",
    "            prob.append(proba_anger)\n",
    "            proba_guilt = self.maximum_likelihood_estimation(instance, self.guilt, emotionCorpusSize=self.guiltSize, emotion=\"guilt\")\n",
    "            prob.append(proba_guilt)\n",
    "\n",
    "            proba_joy = self.maximum_likelihood_estimation(instance, self.joy, emotionCorpusSize=self.joySize, emotion=\"joy\")\n",
    "            prob.append(proba_joy)\n",
    "\n",
    "            proba_shame = self.maximum_likelihood_estimation(instance, self.shame, emotionCorpusSize=self.shameSize, emotion=\"shame\")\n",
    "            prob.append(proba_shame)\n",
    "            proba_disgust = self.maximum_likelihood_estimation(instance, self.disgust, emotionCorpusSize=self.disgustSize, emotion=\"disgust\")\n",
    "            prob.append(proba_disgust)\n",
    "\n",
    "            proba_sadness = self.maximum_likelihood_estimation(instance, self.sadness, emotionCorpusSize=self.sadnessSize, emotion=\"sadness\")\n",
    "            prob.append(proba_sadness)\n",
    "            prediction = np.argmax(np.array(prob)) + 1\n",
    "            predictions.append(prediction)\n",
    "            #print(self.classMapping[prediction])\n",
    "        return predictions\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4260, 2)\n",
      "(1066,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\ntemp = []\\nfor i in predictions:\\n    if i == 1:\\n        temp.append(4)\\n    elif i == 2:\\n        temp.append(7)\\n'"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(isear_train_df[\"X\"], isear_train_df[\"Y\"], stratify=isear_train_df[\"Y\"], test_size=0.2, random_state=42)\n",
    "train_df = pd.DataFrame()\n",
    "train_df[\"X\"] = X_train\n",
    "train_df[\"Y\"] = y_train\n",
    "print(train_df.shape)\n",
    "print(y_test.shape)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "nbObj = NaiveBayesClassifier()\n",
    "nbObj.fit(train_df)\n",
    "predictions = nbObj.predict(X_test)\n",
    "\"\"\"\n",
    "temp = []\n",
    "for i in predictions:\n",
    "    if i == 1:\n",
    "        temp.append(4)\n",
    "    elif i == 2:\n",
    "        temp.append(7)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "[4,\n 7,\n 5,\n 3,\n 3,\n 4,\n 4,\n 7,\n 4,\n 1,\n 4,\n 3,\n 6,\n 3,\n 3,\n 1,\n 4,\n 7,\n 5,\n 6,\n 3,\n 4,\n 3,\n 5,\n 5,\n 3,\n 2,\n 4,\n 2,\n 5,\n 7,\n 6,\n 1,\n 6,\n 7,\n 4,\n 4,\n 3,\n 4,\n 1,\n 5,\n 5,\n 4,\n 4,\n 3,\n 3,\n 7,\n 3,\n 4,\n 6,\n 4,\n 7,\n 7,\n 1,\n 1,\n 4,\n 3,\n 5,\n 2,\n 1,\n 5,\n 2,\n 7,\n 3,\n 7,\n 6,\n 6,\n 1,\n 1,\n 7,\n 7,\n 4,\n 2,\n 4,\n 6,\n 1,\n 7,\n 3,\n 2,\n 6,\n 4,\n 7,\n 3,\n 7,\n 2,\n 3,\n 5,\n 3,\n 3,\n 4,\n 1,\n 3,\n 1,\n 2,\n 4,\n 2,\n 3,\n 2,\n 7,\n 7,\n 4,\n 2,\n 3,\n 3,\n 5,\n 5,\n 2,\n 7,\n 7,\n 2,\n 5,\n 7,\n 2,\n 2,\n 3,\n 1,\n 2,\n 7,\n 4,\n 7,\n 3,\n 4,\n 7,\n 7,\n 2,\n 5,\n 5,\n 3,\n 7,\n 4,\n 7,\n 7,\n 4,\n 6,\n 3,\n 7,\n 7,\n 2,\n 2,\n 1,\n 1,\n 3,\n 3,\n 7,\n 4,\n 5,\n 1,\n 3,\n 6,\n 4,\n 2,\n 7,\n 7,\n 1,\n 1,\n 3,\n 5,\n 3,\n 7,\n 7,\n 7,\n 1,\n 6,\n 7,\n 1,\n 2,\n 7,\n 6,\n 7,\n 4,\n 4,\n 1,\n 1,\n 4,\n 1,\n 4,\n 3,\n 1,\n 5,\n 4,\n 3,\n 1,\n 7,\n 7,\n 2,\n 1,\n 1,\n 4,\n 5,\n 4,\n 3,\n 3,\n 2,\n 3,\n 4,\n 6,\n 2,\n 3,\n 6,\n 6,\n 5,\n 7,\n 2,\n 7,\n 4,\n 3,\n 3,\n 3,\n 2,\n 5,\n 4,\n 3,\n 2,\n 2,\n 3,\n 6,\n 7,\n 5,\n 6,\n 5,\n 4,\n 3,\n 4,\n 7,\n 5,\n 3,\n 4,\n 4,\n 5,\n 4,\n 6,\n 3,\n 6,\n 3,\n 7,\n 5,\n 2,\n 4,\n 3,\n 4,\n 4,\n 7,\n 6,\n 5,\n 4,\n 1,\n 1,\n 3,\n 2,\n 5,\n 6,\n 6,\n 1,\n 2,\n 4,\n 4,\n 7,\n 1,\n 3,\n 7,\n 7,\n 6,\n 7,\n 3,\n 7,\n 3,\n 6,\n 4,\n 4,\n 3,\n 6,\n 3,\n 3,\n 1,\n 4,\n 1,\n 1,\n 1,\n 4,\n 4,\n 1,\n 6,\n 7,\n 2,\n 3,\n 3,\n 6,\n 5,\n 1,\n 1,\n 7,\n 7,\n 1,\n 7,\n 1,\n 4,\n 7,\n 1,\n 7,\n 1,\n 6,\n 4,\n 2,\n 1,\n 6,\n 1,\n 1,\n 4,\n 4,\n 7,\n 4,\n 2,\n 2,\n 4,\n 1,\n 5,\n 4,\n 6,\n 4,\n 1,\n 7,\n 7,\n 2,\n 1,\n 1,\n 4,\n 6,\n 5,\n 4,\n 3,\n 6,\n 3,\n 3,\n 3,\n 3,\n 6,\n 3,\n 6,\n 4,\n 3,\n 6,\n 1,\n 7,\n 2,\n 4,\n 7,\n 5,\n 2,\n 4,\n 3,\n 1,\n 5,\n 4,\n 7,\n 4,\n 4,\n 1,\n 4,\n 7,\n 2,\n 7,\n 2,\n 1,\n 1,\n 4,\n 3,\n 7,\n 4,\n 7,\n 4,\n 4,\n 3,\n 2,\n 1,\n 7,\n 7,\n 7,\n 3,\n 4,\n 4,\n 6,\n 1,\n 1,\n 3,\n 2,\n 5,\n 1,\n 7,\n 7,\n 1,\n 6,\n 5,\n 3,\n 5,\n 1,\n 7,\n 3,\n 6,\n 7,\n 7,\n 1,\n 5,\n 3,\n 3,\n 7,\n 6,\n 4,\n 3,\n 7,\n 2,\n 2,\n 2,\n 2,\n 1,\n 3,\n 7,\n 1,\n 3,\n 7,\n 1,\n 4,\n 4,\n 4,\n 3,\n 3,\n 4,\n 4,\n 5,\n 4,\n 3,\n 1,\n 4,\n 7,\n 2,\n 1,\n 7,\n 4,\n 4,\n 7,\n 7,\n 3,\n 5,\n 1,\n 3,\n 1,\n 7,\n 1,\n 3,\n 7,\n 4,\n 1,\n 2,\n 4,\n 2,\n 2,\n 3,\n 1,\n 7,\n 7,\n 4,\n 4,\n 1,\n 3,\n 5,\n 4,\n 7,\n 5,\n 2,\n 1,\n 7,\n 1,\n 5,\n 3,\n 4,\n 2,\n 3,\n 2,\n 6,\n 7,\n 5,\n 5,\n 2,\n 4,\n 6,\n 3,\n 5,\n 1,\n 2,\n 1,\n 3,\n 3,\n 5,\n 5,\n 3,\n 7,\n 1,\n 4,\n 5,\n 5,\n 1,\n 3,\n 3,\n 2,\n 4,\n 7,\n 4,\n 7,\n 1,\n 1,\n 1,\n 7,\n 7,\n 4,\n 3,\n 3,\n 4,\n 3,\n 7,\n 3,\n 4,\n 7,\n 7,\n 5,\n 5,\n 3,\n 1,\n 4,\n 1,\n 3,\n 7,\n 4,\n 4,\n 4,\n 3,\n 1,\n 3,\n 3,\n 7,\n 7,\n 4,\n 6,\n 3,\n 6,\n 4,\n 5,\n 4,\n 1,\n 2,\n 4,\n 7,\n 4,\n 6,\n 2,\n 1,\n 2,\n 1,\n 4,\n 2,\n 4,\n 6,\n 5,\n 7,\n 3,\n 4,\n 6,\n 1,\n 6,\n 6,\n 5,\n 7,\n 3,\n 4,\n 1,\n 2,\n 5,\n 7,\n 5,\n 5,\n 4,\n 5,\n 6,\n 4,\n 3,\n 5,\n 3,\n 7,\n 5,\n 4,\n 3,\n 1,\n 6,\n 6,\n 7,\n 3,\n 1,\n 3,\n 6,\n 1,\n 5,\n 1,\n 3,\n 6,\n 3,\n 3,\n 2,\n 7,\n 6,\n 7,\n 4,\n 1,\n 5,\n 3,\n 6,\n 7,\n 1,\n 6,\n 1,\n 2,\n 3,\n 3,\n 3,\n 7,\n 2,\n 1,\n 6,\n 1,\n 6,\n 5,\n 5,\n 1,\n 3,\n 6,\n 2,\n 5,\n 4,\n 4,\n 4,\n 2,\n 2,\n 7,\n 4,\n 4,\n 7,\n 6,\n 7,\n 3,\n 3,\n 2,\n 6,\n 5,\n 3,\n 3,\n 6,\n 1,\n 6,\n 4,\n 3,\n 5,\n 6,\n 6,\n 1,\n 7,\n 5,\n 4,\n 3,\n 3,\n 1,\n 4,\n 4,\n 4,\n 3,\n 2,\n 6,\n 4,\n 3,\n 6,\n 2,\n 5,\n 7,\n 4,\n 6,\n 1,\n 3,\n 1,\n 4,\n 6,\n 7,\n 1,\n 1,\n 7,\n 2,\n 6,\n 1,\n 4,\n 3,\n 6,\n 2,\n 7,\n 4,\n 6,\n 2,\n 1,\n 1,\n 6,\n 1,\n 2,\n 2,\n 4,\n 5,\n 5,\n 2,\n 1,\n 4,\n 3,\n 1,\n 2,\n 7,\n 4,\n 3,\n 3,\n 3,\n 6,\n 1,\n 4,\n 6,\n 7,\n 3,\n 2,\n 1,\n 4,\n 7,\n 6,\n 7,\n 6,\n 3,\n 4,\n 2,\n 6,\n 5,\n 2,\n 2,\n 6,\n 6,\n 7,\n 3,\n 2,\n 3,\n 7,\n 5,\n 1,\n 3,\n 7,\n 6,\n 4,\n 4,\n 3,\n 6,\n 5,\n 2,\n 3,\n 4,\n 7,\n 1,\n 2,\n 4,\n 6,\n 7,\n 2,\n 7,\n 1,\n 7,\n 3,\n 7,\n 3,\n 4,\n 1,\n 3,\n 6,\n 3,\n 7,\n 4,\n 3,\n 2,\n 7,\n 7,\n 2,\n 1,\n 6,\n 6,\n 5,\n 7,\n 4,\n 3,\n 2,\n 1,\n 7,\n 3,\n 6,\n 3,\n 1,\n 4,\n 6,\n 3,\n 1,\n 7,\n 3,\n 2,\n 5,\n 2,\n 7,\n 4,\n 7,\n 1,\n 1,\n 7,\n 3,\n 7,\n 2,\n 7,\n 7,\n 1,\n 2,\n 4,\n 1,\n 4,\n 5,\n 4,\n 1,\n 3,\n 3,\n 3,\n 2,\n 5,\n 2,\n 1,\n 7,\n 7,\n 3,\n 1,\n 2,\n 6,\n 1,\n 6,\n 6,\n 2,\n 3,\n 6,\n 6,\n 4,\n 4,\n 3,\n 4,\n 3,\n 1,\n 1,\n 5,\n 1,\n 1,\n 1,\n 6,\n 2,\n 4,\n 6,\n 7,\n 1,\n 6,\n 7,\n 3,\n 3,\n 1,\n 1,\n 7,\n 6,\n 4,\n 6,\n 4,\n 5,\n 4,\n 4,\n 4,\n 1,\n 1,\n 4,\n 2,\n 2,\n 4,\n 6,\n 3,\n 6,\n 5,\n 2,\n 1,\n 7,\n 5,\n 6,\n 3,\n 2,\n 3,\n 7,\n 3,\n 4,\n 4,\n 1,\n 1,\n 6,\n 3,\n 6,\n 4,\n 7,\n 7,\n 3,\n 2,\n 1,\n 1,\n 1,\n 1,\n 6,\n 3,\n 7,\n 4,\n 7,\n 6,\n 7,\n 4,\n 2,\n 6,\n 6,\n 1,\n 4,\n 7,\n 6,\n 3,\n 4,\n 6,\n 4,\n 7,\n 4,\n 5,\n 6,\n 4,\n 4,\n 4,\n 1,\n 4,\n 3,\n 4,\n 5,\n 1,\n 3,\n 4,\n 1,\n 2,\n 1,\n 3,\n 7,\n 1,\n 4,\n 2,\n 6,\n 7,\n 5,\n 7,\n 6,\n 4,\n 6,\n 7,\n 5,\n 7,\n 3,\n 5,\n 7,\n 7,\n 7,\n 3,\n 4,\n 7,\n 7,\n 3,\n 4,\n 1,\n 2,\n 6,\n 3,\n 4,\n 4,\n 7,\n 7,\n 1,\n 4,\n 3,\n 4,\n 2,\n 4,\n 4,\n 7,\n 7,\n 3,\n 7,\n 3,\n 2,\n ...]"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "# Recall\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class evaluation:\n",
    "    def __init__(self, y_actual, y_pred):\n",
    "        self.y_actual = np.array(y_actual)\n",
    "        #print(self.y_actual)\n",
    "        self.y_pred = np.array(y_pred)\n",
    "        #print(self.y_pred)\n",
    "\n",
    "    def confusion_matrix(self, actual, pred):\n",
    "        tp = fp = tn = fn = 0\n",
    "        for i, j in zip(actual, pred):\n",
    "            if i == 1:\n",
    "                # positive\n",
    "                if i == j:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "            else:\n",
    "                # negative\n",
    "                if i == j:\n",
    "                    tn += 1\n",
    "                else:\n",
    "                    fn += 1\n",
    "        cf = pd.DataFrame([[tp, fp], [fn, tn]], columns=[\"actual_pos\", \"actual_neg\"], index=[\"pred_pos\", \"pred_neg\"])\n",
    "        return cf, tp, fp, tn, fn\n",
    "\n",
    "    def recall(self, actual, pred):\n",
    "        cf, tp, fp, tn, fn = self.confusion_matrix(actual, pred)\n",
    "        return tp / (tp+fn)\n",
    "\n",
    "    def precision(self, actual, pred):\n",
    "        cf, tp, fp, tn, fn = self.confusion_matrix(actual, pred)\n",
    "        return tp / (tp+fp)\n",
    "\n",
    "    def f1(self, actual, pred):\n",
    "        # harmonic mean\n",
    "        pr = self.precision(actual, pred)\n",
    "        re = self.recall(actual, pred)\n",
    "        f1 = 2 * ((pr * re) / (pr + re))\n",
    "        return f1\n",
    "\n",
    "    def main(self):\n",
    "        mapping = {1: \"fear\", 2: \"anger\", 3: \"guilt\", 4: \"joy\", 5: \"shame\", 6: \"disgust\", 7: \"sadness\"}\n",
    "        res = {}\n",
    "        for cls in [1.0, 2.0, 3.0, 4.0, 5.0, 6.0 ,7.0]:\n",
    "            c = 0\n",
    "            #print(\"Class : \", mapping[cls])\n",
    "            mod_y_actual = []\n",
    "            for i in self.y_actual:\n",
    "                if i == cls:\n",
    "                    c += 1\n",
    "                    mod_y_actual.append(1)\n",
    "                else:\n",
    "                    mod_y_actual.append(0)\n",
    "            mod_y_pred = []\n",
    "            for i in self.y_pred:\n",
    "                if i == cls:\n",
    "                    mod_y_pred.append(1)\n",
    "                else:\n",
    "                    mod_y_pred.append(0)\n",
    "            #print(mod_y_pred)\n",
    "            \"\"\"\n",
    "            print()\n",
    "            print()\n",
    "            print(\"Confusion Matrix : \\n\", self.confusion_matrix(mod_y_actual, mod_y_pred)[0])\n",
    "            print(\"*******************************************************\\n\")\n",
    "            print(\"Precision : \\n\", self.precision(mod_y_actual, mod_y_pred))\n",
    "            print(\"*******************************************************\\n\")\n",
    "            print(\"Recall : \\n\", self.recall(mod_y_actual, mod_y_pred))\n",
    "            print(\"*******************************************************\\n\")\n",
    "            print(\"F1 Score : \\n\", self.f1(mod_y_actual, mod_y_pred))\n",
    "            print()\n",
    "            print()\n",
    "            \"\"\"\n",
    "            temp = [self.precision(mod_y_actual, mod_y_pred), self.recall(mod_y_actual, mod_y_pred), self.f1(mod_y_actual, mod_y_pred), c]\n",
    "            res[mapping[cls]] = temp\n",
    "        res = pd.DataFrame(res, index=[\"Precision\", \"Recall\", \"F1-Score\", \"Count\"]).transpose()\n",
    "\n",
    "        \"\"\"\n",
    "        Macro average calculation\n",
    "        \"\"\"\n",
    "        avg_pr = np.sum((res[\"Precision\"]*res[\"Count\"]))/ np.sum(res[\"Count\"])\n",
    "        avg_re = np.sum((res[\"Recall\"]*res[\"Count\"]))/ np.sum(res[\"Count\"])\n",
    "        avg_f1 = np.sum((res[\"F1-Score\"]*res[\"Count\"]))/ np.sum(res[\"Count\"])\n",
    "        res.loc[\"Macro_Average\"] = [avg_pr, avg_re, avg_f1, np.sum(res[\"Count\"])]\n",
    "        #res = pd.concat([res, pd.DataFrame([avg_pr, avg_re, avg_f1, np.sum(res[\"Count\"])]).transpose()])\n",
    "\n",
    "        flattened_index = [\"Fear-Precision\", \"Fear-Recall\", \"Fear-F1score\", \"Fear-Count\",\n",
    "                           \"Anger-Precision\", \"Anger-Recall\", \"Anger-F1score\", \"Anger-Count\",\n",
    "                           \"Guilt-Precision\", \"Guilt-Recall\", \"Guilt-F1score\", \"Guilt-Count\",\n",
    "                           \"Joy-Precision\", \"Joy-Recall\", \"Joy-F1score\", \"Joy-Count\",\n",
    "                           \"Shame-Precision\", \"Shame-Recall\", \"Shame-F1score\", \"Shame-Count\",\n",
    "                           \"Disgust-Precision\", \"Disgust-Recall\", \"Disgust-F1score\", \"Disgust-Count\",\n",
    "                           \"Sadness-Precision\", \"Sadness-Recall\", \"Sadness-F1score\", \"Sadness-Count\",\n",
    "                           \"Macro-Average-Precision\", \"Macro-Average-Recall\", \"Macro-Average-F1score\", \"Macro-Average-Count\"]\n",
    "        res_flattened = pd.DataFrame(res.to_numpy().flatten(), index=flattened_index).transpose()\n",
    "        return res_flattened, res\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "               Precision    Recall  F1-Score   Count\nfear            0.640000  0.578313  0.607595   150.0\nanger           0.355263  0.461538  0.401487   152.0\nguilt           0.450980  0.367021  0.404692   153.0\njoy             0.628205  0.507772  0.561605   156.0\nshame           0.342105  0.530612  0.416000   152.0\ndisgust         0.476821  0.590164  0.527473   151.0\nsadness         0.644737  0.538462  0.586826   152.0\nMacro_Average   0.505629  0.510208  0.500724  1066.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1-Score</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>fear</th>\n      <td>0.640000</td>\n      <td>0.578313</td>\n      <td>0.607595</td>\n      <td>150.0</td>\n    </tr>\n    <tr>\n      <th>anger</th>\n      <td>0.355263</td>\n      <td>0.461538</td>\n      <td>0.401487</td>\n      <td>152.0</td>\n    </tr>\n    <tr>\n      <th>guilt</th>\n      <td>0.450980</td>\n      <td>0.367021</td>\n      <td>0.404692</td>\n      <td>153.0</td>\n    </tr>\n    <tr>\n      <th>joy</th>\n      <td>0.628205</td>\n      <td>0.507772</td>\n      <td>0.561605</td>\n      <td>156.0</td>\n    </tr>\n    <tr>\n      <th>shame</th>\n      <td>0.342105</td>\n      <td>0.530612</td>\n      <td>0.416000</td>\n      <td>152.0</td>\n    </tr>\n    <tr>\n      <th>disgust</th>\n      <td>0.476821</td>\n      <td>0.590164</td>\n      <td>0.527473</td>\n      <td>151.0</td>\n    </tr>\n    <tr>\n      <th>sadness</th>\n      <td>0.644737</td>\n      <td>0.538462</td>\n      <td>0.586826</td>\n      <td>152.0</td>\n    </tr>\n    <tr>\n      <th>Macro_Average</th>\n      <td>0.505629</td>\n      <td>0.510208</td>\n      <td>0.500724</td>\n      <td>1066.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "evalObj = evaluation(y_actual=y_test, y_pred=predictions)\n",
    "evalObj.main()[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8214285714285714\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c = 0\n",
    "for i, j in zip(y_test, temp):\n",
    "    if int(i) == j:\n",
    "        c += 1\n",
    "print(c/len(y_test))\n",
    "\n",
    "\"accuracy with only joy and sadness = 82%, with 80:20 train:test split\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}