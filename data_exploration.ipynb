{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ItishaYadav1/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": "         0             1        2     3    4        5         6      7  \\\n0    Anger  Anticipation  Disgust   ---  Joy      ---       ---    ---   \n1      ---  Anticipation      ---   ---  Joy      ---  Surprise    ---   \n2    Anger  Anticipation  Disgust  Fear  ---  Sadness       ---    ---   \n3    Anger           ---      ---   ---  Joy      ---       ---  Trust   \n4    Anger  Anticipation  Disgust   ---  ---  Sadness       ---    ---   \n..     ...           ...      ...   ...  ...      ...       ...    ...   \n287  Anger           ---  Disgust   ---  ---  Sadness       ---    ---   \n288    ---           ---      ---   ---  ---  Sadness       ---  Trust   \n289  Anger  Anticipation  Disgust   ---  ---  Sadness       ---    ---   \n290  Anger           ---  Disgust   ---  ---  Sadness       ---    ---   \n291  Anger           ---  Disgust   ---  ---      ---  Surprise    ---   \n\n                                                     8  \n0    on a side note, just because you think smtg is...  \n1    Woah the hashtag puts the rainbow heart itself...  \n2    I refuse 2comply w/Bad laws. Just Because #SCO...  \n3    Just owned a woman who works for planned paren...  \n4    If it's getting old maybe you should stop call...  \n..                                                 ...  \n287  There's a law protecting unborn eagles, but no...  \n288  I am 1 in 3... I have had an abortion #Abortio...  \n289  How dare you say my sexual preference is a cho...  \n290  Equal rights for those 'born that way', no rig...  \n291  #POTUS seals his legacy w/ 1/2 doz wins. The #...  \n\n[292 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Anger</td>\n      <td>Anticipation</td>\n      <td>Disgust</td>\n      <td>---</td>\n      <td>Joy</td>\n      <td>---</td>\n      <td>---</td>\n      <td>---</td>\n      <td>on a side note, just because you think smtg is...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>---</td>\n      <td>Anticipation</td>\n      <td>---</td>\n      <td>---</td>\n      <td>Joy</td>\n      <td>---</td>\n      <td>Surprise</td>\n      <td>---</td>\n      <td>Woah the hashtag puts the rainbow heart itself...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Anger</td>\n      <td>Anticipation</td>\n      <td>Disgust</td>\n      <td>Fear</td>\n      <td>---</td>\n      <td>Sadness</td>\n      <td>---</td>\n      <td>---</td>\n      <td>I refuse 2comply w/Bad laws. Just Because #SCO...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Anger</td>\n      <td>---</td>\n      <td>---</td>\n      <td>---</td>\n      <td>Joy</td>\n      <td>---</td>\n      <td>---</td>\n      <td>Trust</td>\n      <td>Just owned a woman who works for planned paren...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Anger</td>\n      <td>Anticipation</td>\n      <td>Disgust</td>\n      <td>---</td>\n      <td>---</td>\n      <td>Sadness</td>\n      <td>---</td>\n      <td>---</td>\n      <td>If it's getting old maybe you should stop call...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>287</th>\n      <td>Anger</td>\n      <td>---</td>\n      <td>Disgust</td>\n      <td>---</td>\n      <td>---</td>\n      <td>Sadness</td>\n      <td>---</td>\n      <td>---</td>\n      <td>There's a law protecting unborn eagles, but no...</td>\n    </tr>\n    <tr>\n      <th>288</th>\n      <td>---</td>\n      <td>---</td>\n      <td>---</td>\n      <td>---</td>\n      <td>---</td>\n      <td>Sadness</td>\n      <td>---</td>\n      <td>Trust</td>\n      <td>I am 1 in 3... I have had an abortion #Abortio...</td>\n    </tr>\n    <tr>\n      <th>289</th>\n      <td>Anger</td>\n      <td>Anticipation</td>\n      <td>Disgust</td>\n      <td>---</td>\n      <td>---</td>\n      <td>Sadness</td>\n      <td>---</td>\n      <td>---</td>\n      <td>How dare you say my sexual preference is a cho...</td>\n    </tr>\n    <tr>\n      <th>290</th>\n      <td>Anger</td>\n      <td>---</td>\n      <td>Disgust</td>\n      <td>---</td>\n      <td>---</td>\n      <td>Sadness</td>\n      <td>---</td>\n      <td>---</td>\n      <td>Equal rights for those 'born that way', no rig...</td>\n    </tr>\n    <tr>\n      <th>291</th>\n      <td>Anger</td>\n      <td>---</td>\n      <td>Disgust</td>\n      <td>---</td>\n      <td>---</td>\n      <td>---</td>\n      <td>Surprise</td>\n      <td>---</td>\n      <td>#POTUS seals his legacy w/ 1/2 doz wins. The #...</td>\n    </tr>\n  </tbody>\n</table>\n<p>292 rows Ã— 9 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"./ssec/val.csv\", error_bad_lines=False, header=None, delimiter=\"\\t\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Details # Multi-label-classification\n",
    "# Emotions tags:\n",
    "Anger, Anticipation, Disgust, Fear, Joy, Sadness, Surprise, Trust\n",
    "train.csv = 2622\n",
    "test.csv = 1956\n",
    "val.csv = 292"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5333, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ItishaYadav1/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "b'Skipping line 119: expected 2 fields, saw 7\\nSkipping line 1213: expected 2 fields, saw 4\\nSkipping line 2323: expected 2 fields, saw 3\\nSkipping line 2803: expected 2 fields, saw 3\\nSkipping line 3630: expected 2 fields, saw 4\\nSkipping line 4635: expected 2 fields, saw 5\\nSkipping line 4797: expected 2 fields, saw 4\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": "4.0    777\n3.0    766\n7.0    760\n2.0    758\n5.0    757\n6.0    757\n1.0    751\nName: 0, dtype: int64"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mapping = {\"fear\": 1, \"anger\": 2, \"guilt\": 3, \"joy\": 4, \"shame\": 5, \"disgust\": 6, \"sadness\": 7}\n",
    "isear_train_df = pd.read_csv(\"./isear/isear-train.csv\", error_bad_lines=False, header=None)\n",
    "\n",
    "\n",
    "mapped_emotions = isear_train_df[0].map(mapping)\n",
    "isear_train_df[0] = mapped_emotions\n",
    "\n",
    "print(isear_train_df.shape)\n",
    "isear_train_df[0].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Details # Multi-class-classification\n",
    "# Emotions tags:\n",
    "joy, guilt, sadness, anger, shame, disgust, fear\n",
    "train.csv = 5333\n",
    "test.csv = 1146\n",
    "val.csv = 1150"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Fear-Precision  Fear-Recall  Fear-F1score  Fear-Count  Anger-Precision  \\\n0             1.0          1.0           1.0       751.0              1.0   \n\n   Anger-Recall  Anger-F1score  Anger-Count  Guilt-Precision  Guilt-Recall  \\\n0           1.0            1.0        758.0              1.0           1.0   \n\n   ...  Disgust-F1score  Disgust-Count  Sadness-Precision  Sadness-Recall  \\\n0  ...              1.0          757.0                1.0             1.0   \n\n   Sadness-F1score  Sadness-Count  Macro-Average-Precision  \\\n0              1.0          760.0                      1.0   \n\n   Macro-Average-Recall  Macro-Average-F1score  Macro-Average-Count  \n0                   1.0                    1.0               5326.0  \n\n[1 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Fear-Precision</th>\n      <th>Fear-Recall</th>\n      <th>Fear-F1score</th>\n      <th>Fear-Count</th>\n      <th>Anger-Precision</th>\n      <th>Anger-Recall</th>\n      <th>Anger-F1score</th>\n      <th>Anger-Count</th>\n      <th>Guilt-Precision</th>\n      <th>Guilt-Recall</th>\n      <th>...</th>\n      <th>Disgust-F1score</th>\n      <th>Disgust-Count</th>\n      <th>Sadness-Precision</th>\n      <th>Sadness-Recall</th>\n      <th>Sadness-F1score</th>\n      <th>Sadness-Count</th>\n      <th>Macro-Average-Precision</th>\n      <th>Macro-Average-Recall</th>\n      <th>Macro-Average-F1score</th>\n      <th>Macro-Average-Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>751.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>758.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>757.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>760.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>5326.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows Ã— 32 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class evaluation:\n",
    "    def __init__(self, y_actual, y_pred):\n",
    "        self.y_actual = np.array(y_actual)\n",
    "        #print(self.y_actual)\n",
    "        self.y_pred = np.array(y_pred)\n",
    "        #print(self.y_pred)\n",
    "\n",
    "    def confusion_matrix(self, actual, pred):\n",
    "        tp = fp = tn = fn = 0\n",
    "        for i, j in zip(actual, pred):\n",
    "            if i == 1:\n",
    "                # positive\n",
    "                if i == j:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "            else:\n",
    "                # negative\n",
    "                if i == j:\n",
    "                    tn += 1\n",
    "                else:\n",
    "                    fn += 1\n",
    "        cf = pd.DataFrame([[tp, fp], [fn, tn]], columns=[\"actual_pos\", \"actual_neg\"], index=[\"pred_pos\", \"pred_neg\"])\n",
    "        return cf, tp, fp, tn, fn\n",
    "\n",
    "    def recall(self, actual, pred):\n",
    "        cf, tp, fp, tn, fn = self.confusion_matrix(actual, pred)\n",
    "        return tp / (tp+fn)\n",
    "\n",
    "    def precision(self, actual, pred):\n",
    "        cf, tp, fp, tn, fn = self.confusion_matrix(actual, pred)\n",
    "        return tp / (tp+fp)\n",
    "\n",
    "    def f1(self, actual, pred):\n",
    "        # harmonic mean\n",
    "        pr = self.precision(actual, pred)\n",
    "        re = self.recall(actual, pred)\n",
    "        f1 = 2 * ((pr * re) / (pr + re))\n",
    "        return f1\n",
    "\n",
    "    def main(self):\n",
    "        mapping = {1: \"fear\", 2: \"anger\", 3: \"guilt\", 4: \"joy\", 5: \"shame\", 6: \"disgust\", 7: \"sadness\"}\n",
    "        res = {}\n",
    "        for cls in [1.0, 2.0, 3.0, 4.0, 5.0, 6.0 ,7.0]:\n",
    "            c = 0\n",
    "            #print(\"Class : \", mapping[cls])\n",
    "            mod_y_actual = []\n",
    "            for i in self.y_actual:\n",
    "                if i == cls:\n",
    "                    c += 1\n",
    "                    mod_y_actual.append(1)\n",
    "                else:\n",
    "                    mod_y_actual.append(0)\n",
    "            mod_y_pred = []\n",
    "            for i in self.y_pred:\n",
    "                if i == cls:\n",
    "                    mod_y_pred.append(1)\n",
    "                else:\n",
    "                    mod_y_pred.append(0)\n",
    "            #print(mod_y_pred)\n",
    "            \"\"\"\n",
    "            print()\n",
    "            print()\n",
    "            print(\"Confusion Matrix : \\n\", self.confusion_matrix(mod_y_actual, mod_y_pred)[0])\n",
    "            print(\"*******************************************************\\n\")\n",
    "            print(\"Precision : \\n\", self.precision(mod_y_actual, mod_y_pred))\n",
    "            print(\"*******************************************************\\n\")\n",
    "            print(\"Recall : \\n\", self.recall(mod_y_actual, mod_y_pred))\n",
    "            print(\"*******************************************************\\n\")\n",
    "            print(\"F1 Score : \\n\", self.f1(mod_y_actual, mod_y_pred))\n",
    "            print()\n",
    "            print()\n",
    "            \"\"\"\n",
    "            temp = [self.precision(mod_y_actual, mod_y_pred), self.recall(mod_y_actual, mod_y_pred), self.f1(mod_y_actual, mod_y_pred), c]\n",
    "            res[mapping[cls]] = temp\n",
    "        res = pd.DataFrame(res, index=[\"Precision\", \"Recall\", \"F1-Score\", \"Count\"]).transpose()\n",
    "        print(res.shape)\n",
    "        \"\"\"\n",
    "        Macro average calculationd\n",
    "        \"\"\"\n",
    "        avg_pr = np.sum((res[\"Precision\"]*res[\"Count\"]))/ np.sum(res[\"Count\"])\n",
    "        avg_re = np.sum((res[\"Recall\"]*res[\"Count\"]))/ np.sum(res[\"Count\"])\n",
    "        avg_f1 = np.sum((res[\"F1-Score\"]*res[\"Count\"]))/ np.sum(res[\"Count\"])\n",
    "        res.loc[\"Macro_Average\"] = [avg_pr, avg_re, avg_f1, np.sum(res[\"Count\"])]\n",
    "        #res = pd.concat([res, pd.DataFrame([avg_pr, avg_re, avg_f1, np.sum(res[\"Count\"])]).transpose()])\n",
    "\n",
    "        flattened_index = [\"Fear-Precision\", \"Fear-Recall\", \"Fear-F1score\", \"Fear-Count\",\n",
    "                           \"Anger-Precision\", \"Anger-Recall\", \"Anger-F1score\", \"Anger-Count\",\n",
    "                           \"Guilt-Precision\", \"Guilt-Recall\", \"Guilt-F1score\", \"Guilt-Count\",\n",
    "                           \"Joy-Precision\", \"Joy-Recall\", \"Joy-F1score\", \"Joy-Count\",\n",
    "                           \"Shame-Precision\", \"Shame-Recall\", \"Shame-F1score\", \"Shame-Count\",\n",
    "                           \"Disgust-Precision\", \"Disgust-Recall\", \"Disgust-F1score\", \"Disgust-Count\",\n",
    "                           \"Sadness-Precision\", \"Sadness-Recall\", \"Sadness-F1score\", \"Sadness-Count\",\n",
    "                           \"Macro-Average-Precision\", \"Macro-Average-Recall\", \"Macro-Average-F1score\", \"Macro-Average-Count\"]\n",
    "        res_flattened = pd.DataFrame(res.to_numpy().flatten(), index=flattened_index).transpose()\n",
    "        return res_flattened, res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "obj = evaluation(isear_train_df[0], isear_train_df[0])\n",
    "obj.main()[0]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Baseline Method Implementation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "stopwords = {'hers', 'below', \"wouldn't\", 'nor', 'for', 'over', \"hasn't\", 'at', 'shouldn', 'only', 'above', 'itself', 'yourselves', 'what', \"don't\", \"it's\", 'which', 'against', \"that'll\", 'has', 'i', 'his', 'having', 'then', \"shan't\", 'myself', 'do', 'yours', 'up', 'own', 'the', 'same', 'aren', 'few', 'through', 'here', 'whom', 'o', \"aren't\", 'were', 'are', 'both', \"didn't\", 'll', 'again', 'is', 're', \"wasn't\", \"you'll\", 'm', \"haven't\", 'such', 'off', 'of', 'it', 'did', 'into', 'to', 'other', 'was', 'just', 've', \"mustn't\", 'while', 'about', 'each', 'by', 'this', 'isn', 'ourselves', 'in', 'our', 'couldn', 'until', 'where', \"couldn't\", 'ain', \"you'd\", 'all', 'when', 'does', 'before', 'weren', 'y', 'doing', 'than', 'being', 'my', 'mightn', 'yourself', 'with', 'theirs', 'so', \"needn't\", 'a', \"doesn't\", \"isn't\", 'its', 'your', 'if', \"should've\", 'ma', 'can', 'herself', 'but', 'too', 'more', 'her', \"hadn't\", 'hadn', 'there', \"you're\", 'from', 'should', 'we', 'how', 'out', 'once', 'mustn', 'won', 'their', 'don', 'had', 'he', 'or', 'didn', 'd', 'down', 't', \"she's\", 'that', 'himself', 'wouldn', \"you've\", \"mightn't\", 'between', 'them', 'on', 'haven', 'after', 'themselves', 'because', 'and', 'you', 'very', 's', 'these', 'no', 'now', 'him', 'been', 'those', 'during', 'doesn', 'wasn', 'am', 'under', 'an', 'some', 'have', 'me', 'any', 'who', 'shan', 'why', 'will', \"shouldn't\", 'not', 'they', \"won't\", 'needn', 'further', 'most', 'be', 'ours', 'she', 'as', 'hasn', \"weren't\", \"a\", \"''\"}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import re\n",
    "def getHighFreqWordsByEmotion(df, emo_tag):\n",
    "    mapping = {1: \"fear\", 2: \"anger\", 3: \"guilt\", 4: \"joy\", 5: \"shame\", 6: \"disgust\", 7: \"sadness\"}\n",
    "    wordfreq = {}\n",
    "    emodf = df[df[0] == emo_tag]\n",
    "    text = \" \".join(list(emodf[1])).split(\" \")\n",
    "    for word in text:\n",
    "        word = re.sub(\"[^A-Za-z]\", \"\", word).strip().lower()\n",
    "        if word not in stopwords and len(word) > 0:\n",
    "            if word in wordfreq:\n",
    "                wordfreq[word] += 1\n",
    "            else:\n",
    "                wordfreq[word] = 1\n",
    "    sort_orders = sorted(wordfreq.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"Type to Token ratio for \" + mapping[emo_tag] + \" = \", round(len(set(text))/len(text), 2))\n",
    "    unqWords = [key for key, value in wordfreq.items()]\n",
    "    return sort_orders, set(unqWords)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type to Token ratio for fear =  0.19\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fear\n",
    "\"\"\"\n",
    "import pickle\n",
    "fear = getHighFreqWordsByEmotion(isear_train_df, 1)\n",
    "fear100, fearset = fear[0][0:100], fear[1]\n",
    "with open('fear100.pickle', 'wb') as handle:\n",
    "    pickle.dump(fear100, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type to Token ratio for anger =  0.2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Anger\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "anger = getHighFreqWordsByEmotion(isear_train_df, 2)\n",
    "anger100, angerset = anger[0][0:100], fear[1]\n",
    "with open('anger100.pickle', 'wb') as handle:\n",
    "    pickle.dump(anger100, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type to Token ratio for guilt =  0.18\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Guilt\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "guilt = getHighFreqWordsByEmotion(isear_train_df, 3)\n",
    "guilt100, guiltset = guilt[0][0:100], guilt[1]\n",
    "with open('guilt100.pickle', 'wb') as handle:\n",
    "    pickle.dump(guilt100, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type to Token ratio for joy =  0.19\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Joy\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "joy = getHighFreqWordsByEmotion(isear_train_df, 4)\n",
    "joy100, joyset = joy[0][0:100], joy[1]\n",
    "with open('joy100.pickle', 'wb') as handle:\n",
    "    pickle.dump(joy100, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type to Token ratio for shame =  0.19\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Shame\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "shame = getHighFreqWordsByEmotion(isear_train_df, 5)\n",
    "shame100, shameset = shame[0][0:100], shame[1]\n",
    "with open('shame100.pickle', 'wb') as handle:\n",
    "    pickle.dump(shame100, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type to Token ratio for disgust =  0.23\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Disgust\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "disgust = getHighFreqWordsByEmotion(isear_train_df, 6)\n",
    "disgust100, disgustset = disgust[0][0:100], disgust[1]\n",
    "with open('disgust100.pickle', 'wb') as handle:\n",
    "    pickle.dump(disgust100, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type to Token ratio for sadness =  0.18\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('died', 132),\n ('sad', 120),\n ('friend', 117),\n ('felt', 92),\n ('time', 73),\n ('father', 60),\n ('away', 60),\n ('friends', 60),\n ('death', 55),\n ('one', 55),\n ('years', 55),\n ('mother', 51),\n ('close', 51),\n ('home', 45),\n ('left', 42),\n ('passed', 39),\n ('boyfriend', 39),\n ('could', 37),\n ('mine', 35),\n ('told', 34),\n ('would', 34),\n ('grandmother', 33),\n ('thought', 32),\n ('heard', 31),\n ('good', 31),\n ('family', 30),\n ('year', 30),\n ('go', 30),\n ('girl', 29),\n ('relationship', 29),\n ('grandfather', 28),\n ('school', 28),\n ('went', 28),\n ('brother', 27),\n ('got', 27),\n ('sadness', 27),\n ('see', 27),\n ('failed', 26),\n ('day', 26),\n ('old', 26),\n ('made', 26),\n ('sister', 26),\n ('girlfriend', 25),\n ('back', 25),\n ('saw', 25),\n ('first', 24),\n ('cancer', 24),\n ('much', 24),\n ('accident', 24),\n ('didnt', 23),\n ('ill', 23),\n ('feel', 23),\n ('last', 22),\n ('two', 22),\n ('found', 22),\n ('long', 21),\n ('parents', 21),\n ('really', 21),\n ('person', 21),\n ('know', 21),\n ('car', 21),\n ('days', 21),\n ('like', 20),\n ('wanted', 20),\n ('university', 19),\n ('life', 19),\n ('lost', 19),\n ('best', 18),\n ('several', 18),\n ('leave', 18),\n ('months', 17),\n ('hospital', 17),\n ('received', 17),\n ('funeral', 17),\n ('ago', 17),\n ('going', 16),\n ('situation', 16),\n ('another', 16),\n ('alone', 16),\n ('later', 16),\n ('way', 15),\n ('uncle', 15),\n ('separated', 15),\n ('relative', 15),\n ('news', 15),\n ('dog', 14),\n ('people', 14),\n ('lot', 14),\n ('bad', 14),\n ('something', 14),\n ('happened', 14),\n ('liked', 14),\n ('many', 14),\n ('loved', 13),\n ('realized', 13),\n ('work', 13),\n ('still', 13),\n ('us', 13),\n ('getting', 13),\n ('couldnt', 13)]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "sadness\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "sadness = getHighFreqWordsByEmotion(isear_train_df, 7)\n",
    "sadness100, sadnessset = sadness[0][0:100], sadness[1]\n",
    "with open('sadness100.pickle', 'wb') as handle:\n",
    "    pickle.dump(sadness100, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "sadness100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "{'maltreated',\n 'aversion',\n 'caterpillar',\n 'cope',\n 'unfair',\n 'tooth',\n 'misbehaved',\n 'metre',\n 'remain',\n 'funny',\n 'somebodys',\n 'summers',\n 'masturbating',\n 'rising',\n 'aged',\n 'ship',\n 'hair',\n 'hurried',\n 'faster',\n 'birthray',\n 'range',\n 'unrequited',\n 'dreadful',\n 'totally',\n 'mind',\n 'programme',\n 'sadnessunpleasantness',\n 'ghost',\n 'tipped',\n 'mixing',\n 'armed',\n 'trains',\n 'dump',\n 'neurologism',\n 'dry',\n 'deceiving',\n 'authority',\n 'harm',\n 'insulted',\n 'soiling',\n 'meantime',\n 'crumbs',\n 'collection',\n 'adepts',\n 'aggressions',\n 'frigthened',\n 'pulsing',\n 'bell',\n 'whe',\n 'rejected',\n 'tought',\n 'roche',\n 'grilles',\n 'throat',\n 'residing',\n 'santander',\n 'afthur',\n 'dreamed',\n 'extermination',\n 'hernan',\n 'sleepless',\n 'zone',\n 'diving',\n 'fiancts',\n 'hereafter',\n 'cease',\n 'coma',\n 'prospect',\n 'ferryboat',\n 'blame',\n 'negligence',\n 'deeply',\n 'factory',\n 'windy',\n 'convulsively',\n 'mistook',\n 'thatched',\n 'diseases',\n 'slipped',\n 'dinning',\n 'magazine',\n 'plovdivbourgas',\n 'passenger',\n 'duration',\n 'applicable',\n 'maria',\n 'killing',\n 'suit',\n 'insulting',\n 'retired',\n 'supporting',\n 'encountering',\n 'overtures',\n 'auckland',\n 'sore',\n 'rigid',\n 'snout',\n 'piano',\n 'snacks',\n 'aisle',\n 'messy',\n 'guardian',\n 'unwell',\n 'conditions',\n 'mucous',\n 'unsure',\n 'sing',\n 'surface',\n 'canccer',\n 'flame',\n 'custody',\n 'pudding',\n 'strange',\n 'blanket',\n 'boredom',\n 'spreading',\n 'vile',\n 'exceptional',\n 'braced',\n 'elaborate',\n 'glassy',\n 'scream',\n 'teen',\n 'weak',\n 'river',\n 'quarreled',\n 'homes',\n 'pieces',\n 'request',\n 'nominees',\n 'pouch',\n 'ruining',\n 'yearrs',\n 'coins',\n 'vienna',\n 'imagining',\n 'excitement',\n 'roaches',\n 'fulfilling',\n 'landscape',\n 'la',\n 'avoid',\n 'missiles',\n 'kapenta',\n 'defenceless',\n 'greasy',\n 'asciatic',\n 'los',\n 'machine',\n 'probably',\n 'bits',\n 'tonguetied',\n 'frieend',\n 'show',\n 'enrolling',\n 'distasteful',\n 'icy',\n 'translator',\n 'anaunts',\n 'saturday',\n 'adapt',\n 'pts',\n 'difference',\n 'estimation',\n 'nuts',\n 'rude',\n 'spanked',\n 'sixteen',\n 'caring',\n 'paulo',\n 'meatfactory',\n 'ranger',\n 'urinating',\n 'asleep',\n 'awful',\n 'spoilt',\n 'comment',\n 'rejection',\n 'forniture',\n 'value',\n 'dedication',\n 'paste',\n 'bkoke',\n 'defecating',\n 'overtook',\n 'cellar',\n 'cost',\n 'accusers',\n 'tears',\n 'grovelling',\n 'palsy',\n 'bourgas',\n 'demonstrators',\n 'argument',\n 'wandered',\n 'emptied',\n 'conflict',\n 'barking',\n 'kilometers',\n 'nation',\n 'unhealthy',\n 'mai',\n 'dropped',\n 'mate',\n 'wiped',\n 'economically',\n 'woulld',\n 'latest',\n 'calling',\n 'reached',\n 'experimenting',\n 'serie',\n 'kinds',\n 'decompsition',\n 'malaysian',\n 'increase',\n 'se',\n 'mexico',\n 'barbecue',\n 'lapa',\n 'discriminate',\n 'brotherinlaw',\n 'beliefs',\n 'nominated',\n 'tolerate',\n 'shot',\n 'meningitis',\n 'spare',\n 'parent',\n 'prekindergarten',\n 'keeping',\n 'movie',\n 'employers',\n 'uni',\n 'attacking',\n 'visa',\n 'cooks',\n 'association',\n 'aeroplane',\n 'folders',\n 'bodies',\n 'schure',\n 'peeling',\n 'shower',\n 'hitchcock',\n 'reflect',\n 'broadcast',\n 'recommend',\n 'faeces',\n 'foolishness',\n 'comments',\n 'transfer',\n 'tavern',\n 'parfume',\n 'believes',\n 'reperbahn',\n 'moving',\n 'constraint',\n 'muddy',\n 'weeds',\n 'flew',\n 'pulp',\n 'depressions',\n 'encouraged',\n 'girls',\n 'action',\n 'excrements',\n 'suffocated',\n 'necrophiliac',\n 'sarcasm',\n 'rugged',\n 'desks',\n 'bum',\n 'deplorable',\n 'pointless',\n 'scrapped',\n 'denmark',\n 'comfort',\n 'sour',\n 'military',\n 'rabid',\n 'speak',\n 'mountains',\n 'exitus',\n 'paranoia',\n 'glands',\n 'inert',\n 'obedient',\n 'useless',\n 'involving',\n 'organize',\n 'object',\n 'mere',\n 'actual',\n 'slopeit',\n 'mattered',\n 'australian',\n 'harbour',\n 'someeone',\n 'maternal',\n 'nz',\n 'australia',\n 'reigning',\n 'sauce',\n 'ice',\n 'monze',\n 'remind',\n 'smoked',\n 'unrealized',\n 'litter',\n 'inhale',\n 'slipperiness',\n 'novel',\n 'talkative',\n 'notify',\n 'tuesday',\n 'user',\n 'idol',\n 'unwilling',\n 'mans',\n 'boasting',\n 'redemption',\n 'rode',\n 'effort',\n 'workmates',\n 'werent',\n 'despair',\n 'eachother',\n 'blacks',\n 'pitch',\n 'mountain',\n 'prevent',\n 'advantage',\n 'dates',\n 'biked',\n 'gloom',\n 'area',\n 'mirror',\n 'ethiopia',\n 'relates',\n 'sung',\n 'turn',\n 'burgled',\n 'gays',\n 'childishly',\n 'rave',\n 'comfortable',\n 'insect',\n 'mates',\n 'dish',\n 'built',\n 'epileptic',\n 'assassination',\n 'recluse',\n 'complains',\n 'distroy',\n 'turkey',\n 'scleral',\n 'segments',\n 'walls',\n 'traveling',\n 'poisonous',\n 'groups',\n 'hut',\n 'biological',\n 'broke',\n 'adjoining',\n 'suspended',\n 'jailed',\n 'repress',\n 'bench',\n 'laziness',\n 'kissing',\n 'carried',\n 'according',\n 'frost',\n 'metres',\n 'skating',\n 'restlessness',\n 'sold',\n 'knee',\n 'springs',\n 'flute',\n 'affected',\n 'ended',\n 'ceremonies',\n 'injection',\n 'itching',\n 'mothers',\n 'land',\n 'magazines',\n 'lamps',\n 'attempting',\n 'cheered',\n 'stomaches',\n 'slogans',\n 'anyway',\n 'questionable',\n 'riding',\n 'regularly',\n 'roadblock',\n 'kitchen',\n 'drowning',\n 'horizon',\n 'size',\n 'painful',\n 'deer',\n 'failing',\n 'flames',\n 'entertaining',\n 'traffic',\n 'elephant',\n 'shout',\n 'toilet',\n 'rotten',\n 'pittied',\n 'dusty',\n 'conduct',\n 'original',\n 'resources',\n 'commentary',\n 'fans',\n 'someonne',\n 'outward',\n 'paternal',\n 'treats',\n 'startwar',\n 'qualify',\n 'heavyly',\n 'york',\n 'robbers',\n 'recreational',\n 'rooms',\n 'extremes',\n 'dash',\n 'mechanical',\n 'hamburger',\n 'dekker',\n 'latin',\n 'justifiable',\n 'severely',\n 'revolve',\n 'diet',\n 'suffering',\n 'sounds',\n 'rattling',\n 'sharply',\n 'biology',\n 'putrification',\n 'questionnaire',\n 'sierra',\n 'deep',\n 'flashed',\n 'noon',\n 'moss',\n 'white',\n 'neighbour',\n 'granted',\n 'serious',\n 'reference',\n 'disagreed',\n 'employment',\n 'threateningly',\n 'dangerously',\n 'goes',\n 'bombs',\n 'grandmothers',\n 'damp',\n 'unbearable',\n 'salvador',\n 'comes',\n 'paying',\n 'thank',\n 'abandoned',\n 'crept',\n 'diagnosed',\n 'bully',\n 'previous',\n 'comparing',\n 'excused',\n 'descriptions',\n 'surgeon',\n 'dishonestly',\n 'seal',\n 'realizes',\n 'crashing',\n 'business',\n 'grassparakeet',\n 'punished',\n 'elses',\n 'wall',\n 'wouldnt',\n 'cowardliness',\n 'abortion',\n 'packed',\n 'landlady',\n 'dynasty',\n 'quiz',\n 'motorway',\n 'remuera',\n 'demonstrated',\n 'preenrollment',\n 'liver',\n 'consciously',\n 'challenged',\n 'zigzagging',\n 'except',\n 'burnt',\n 'moral',\n 'calmed',\n 'directly',\n 'nearest',\n 'behave',\n 'betrayed',\n 'silly',\n 'swerving',\n 'youngsters',\n 'goodbye',\n 'democrat',\n 'obstinate',\n 'smart',\n 'principles',\n 'booked',\n 'prospects',\n 'miles',\n 'bandwagon',\n 'chick',\n 'fence',\n 'occassion',\n 'stack',\n 'aware',\n 'filthy',\n 'peoplie',\n 'bets',\n 'personally',\n 'robberies',\n 'probation',\n 'harrassed',\n 'occasional',\n 'united',\n 'cool',\n 'ghandi',\n 'vandalism',\n 'provided',\n 'please',\n 'coin',\n 'tradeentrance',\n 'chased',\n 'insipid',\n 'caught',\n 'tb',\n 'burping',\n 'stranger',\n 'sexistly',\n 'teams',\n 'critically',\n 'drawers',\n 'protruding',\n 'locking',\n 'saddening',\n 'column',\n 'witch',\n 'learns',\n 'theatre',\n 'eager',\n 'insisted',\n 'probaly',\n 'forest',\n 'establishment',\n 'powerlessness',\n 'hashish',\n 'cars',\n 'unfortunately',\n 'damaged',\n 'guests',\n 'names',\n 'hamster',\n 'ist',\n 'prisoners',\n 'ideas',\n 'nevertheless',\n 'steady',\n 'escort',\n 'dreaming',\n 'horse',\n 'tapped',\n 'seems',\n 'bit',\n 'nephews',\n 'attackad',\n 'breath',\n 'orderly',\n 'concerned',\n 'immigrate',\n 'handbag',\n 'hampering',\n 'husbands',\n 'desagreable',\n 'motherinlaw',\n 'septic',\n 'childish',\n 'situational',\n 'summoned',\n 'crack',\n 'lt',\n 'babysitting',\n 'perfomance',\n 'transferred',\n 'crises',\n 'aboriginal',\n 'motion',\n 'replaced',\n 'cheerfulness',\n 'fight',\n 'walks',\n 'accosted',\n 'terminally',\n 'expound',\n 'identify',\n 'pouring',\n 'waste',\n 'crush',\n 'invite',\n 'nonsense',\n 'balance',\n 'maori',\n 'upon',\n 'brake',\n 'victim',\n 'chili',\n 'assaulting',\n 'blantyre',\n 'korean',\n 'teachers',\n 'remaining',\n 'panhandling',\n 'notes',\n 'catch',\n 'murderously',\n 'cemetery',\n 'arm',\n 'penetration',\n 'nights',\n 'intoduced',\n 'provoke',\n 'sad',\n 'upper',\n 'maybe',\n 'papua',\n 'nieghbour',\n 'porch',\n 'wooden',\n 'bophal',\n 'imprisoned',\n 'lusaka',\n 'gluttony',\n 'narayan',\n 'sticken',\n 'distant',\n 'criticisms',\n 'ray',\n 'retention',\n 'thirteen',\n 'convenient',\n 'selfconfidence',\n 'skijump',\n 'horrot',\n 'proceeded',\n 'bowls',\n 'tarts',\n 'tune',\n 'foretell',\n 'amounts',\n 'blow',\n 'bite',\n 'unwanted',\n 'angeles',\n 'attitudes',\n 'america',\n 'illustration',\n 'swollen',\n 'vomitted',\n 'gesturing',\n 'gripped',\n 'mucus',\n 'paranormal',\n 'bread',\n 'pushing',\n 'diesel',\n 'nearer',\n 'witchcraft',\n 'gained',\n 'loss',\n 'approach',\n 'gesture',\n 'john',\n 'yeaterday',\n 'habits',\n 'anguish',\n 'encountered',\n 'diagnosis',\n 'agitation',\n 'subjugated',\n 'cooked',\n 'odd',\n 'raped',\n 'oiut',\n 'journalism',\n 'attracting',\n 'wd',\n 'herd',\n 'utrecht',\n 'lessons',\n 'african',\n 'truffaut',\n 'k',\n 'magic',\n 'fully',\n 'mainland',\n 'brakes',\n 'queue',\n 'biochemistry',\n 'fat',\n 'stories',\n 'climb',\n 'traditional',\n 'glued',\n 'defend',\n 'steal',\n 'star',\n 'savagery',\n 'beaten',\n 'bunk',\n 'disappoint',\n 'overdosed',\n 'crippled',\n 'dealers',\n 'facilities',\n 'spectators',\n 'buay',\n 'whose',\n 'profound',\n 'trailer',\n 'inlaws',\n 'pushed',\n 'mororcycle',\n 'imposter',\n 'wounded',\n 'mix',\n 'noisily',\n 'twentieth',\n 'source',\n 'millions',\n 'thunder',\n 'attack',\n 'income',\n 'pushbike',\n 'mouthful',\n 'monsters',\n 'purse',\n 'available',\n 'dictation',\n 'slippery',\n 'building',\n 'hinged',\n 'jaya',\n 'keen',\n 'usally',\n 'offended',\n 'mining',\n 'prior',\n 'robbed',\n 'eldest',\n 'dissect',\n 'ta',\n 'gooey',\n 'tape',\n 'practices',\n 'someboby',\n 'corpse',\n 'kerb',\n 'influence',\n 'mankind',\n 'spree',\n 'rehearse',\n 'hsc',\n 'dress',\n 'examiners',\n 'kiosque',\n 'grenade',\n 'patrols',\n 'sensation',\n 'orientation',\n 'pot',\n 'substance',\n 'crime',\n 'intoxicated',\n 'revenge',\n 'denied',\n 'bullets',\n 'mummys',\n 'risky',\n 'chapel',\n 'immensely',\n 'derivations',\n 'duster',\n 'eat',\n 'eternal',\n 'onto',\n 'bills',\n 'sessions',\n 'predictable',\n 'psalms',\n 'row',\n 'counts',\n 'similarly',\n 'barely',\n 'removed',\n 'utc',\n 'bend',\n 'helpful',\n 'paintings',\n 'eye',\n 'breaking',\n 'disturbing',\n 'burglars',\n 'diameter',\n 'polder',\n 'crimes',\n 'consideration',\n 'hiking',\n 'peolpe',\n 'smelling',\n 'route',\n 'dizzy',\n 'skunk',\n 'thankyou',\n 'reply',\n 'lights',\n 'expressions',\n 'midnight',\n 'victoria',\n 'packets',\n 'farewell',\n 'miracles',\n 'observing',\n 'instant',\n 'leaders',\n 'cigarettes',\n 'reminding',\n 'dangerous',\n 'washing',\n 'men',\n 'compelled',\n 'secluded',\n 'pet',\n 'kicked',\n 'bs',\n 'appered',\n 'interrupt',\n 'outskirts',\n 'amt',\n 'mud',\n 'laying',\n 'screwing',\n 'hiding',\n 'painting',\n 'paranoid',\n 'escape',\n 'closely',\n 'buying',\n 'detention',\n 'kilometres',\n 'den',\n 'attained',\n 'isnt',\n 'instructors',\n 'consequences',\n 'exgirlfriend',\n 'threatened',\n 'ages',\n 'unexpectantly',\n 'mild',\n 'antipornography',\n 'mannner',\n 'tumor',\n 'returning',\n 'act',\n 'spit',\n 'nineteenth',\n 'ticket',\n 'hanging',\n 'overpowering',\n 'prepared',\n 'dirt',\n 'esteem',\n 'tables',\n 'bypass',\n 'account',\n 'invaded',\n 'draw',\n 'opinions',\n 'setbacks',\n 'monday',\n 'juice',\n 'satan',\n 'scrubber',\n 'neighbors',\n 'describing',\n 'iran',\n 'embezzelling',\n 'gun',\n 'government',\n 'drown',\n 'longterm',\n 'stating',\n 'nearaccident',\n 'interrelations',\n 'molesting',\n 'sailors',\n 'adopting',\n 'alright',\n 'easily',\n 'hemorhage',\n 'filtered',\n 'trusts',\n 'molest',\n 'priority',\n 'flattering',\n 'miscarriage',\n 'craps',\n 'necessity',\n 'explanation',\n 'force',\n 'frantois',\n 'served',\n 'celibate',\n 'knows',\n 'women',\n 'expreience',\n 'burglers',\n 'sickbed',\n 'illegitimately',\n 'box',\n 'organization',\n 'excursion',\n 'scraps',\n 'whhen',\n 'mugged',\n 'musical',\n 'nonsmoking',\n 'shut',\n 'control',\n 'feet',\n 'keep',\n 'seperated',\n 'struggle',\n 'brutalized',\n 'wave',\n 'rags',\n 'swim',\n 'tax',\n 'referring',\n 'dorm',\n 'included',\n 'audience',\n 'belong',\n 'presumed',\n 'arcade',\n 'beg',\n 'petrified',\n 'peeped',\n 'poltergist',\n 'bedridden',\n 'leaned',\n 'goddess',\n 'permanently',\n 'air',\n 'hospitalized',\n 'cloudburst',\n 'fuel',\n 'cannot',\n 'proposed',\n 'knife',\n 'chemists',\n 'colleague',\n 'wash',\n 'appointment',\n 'supplies',\n 'studenthouse',\n 'comparable',\n 'dean',\n 'rock',\n 'mistake',\n 'organist',\n 'renounce',\n 'trips',\n 'dim',\n 'cakes',\n 'attempts',\n ...}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "unique fear\n",
    "\"\"\"\n",
    "res = fearset.union(angerset, sadnessset, disgustset) - joyset\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# joy, shame, guilt, negative (fear, anger, sad, disgust)\n",
    "with open('negative.pickle', 'wb') as handle:\n",
    "    pickle.dump(res, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nDataFrame of features:\\nBasline Naive Bayes\\n\\n[0, 1, 0, 1.......], target (1 - 7)\\n'"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Features:\n",
    "1. Type/Token ration (buckets)\n",
    "2. sentence length (buckets)\n",
    "3. presence in fear top 100\n",
    "4. presence in fear unique\n",
    "-------------------\n",
    "Total = 7*2 + 2 = 16 features\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "DataFrame of features:\n",
    "Basline Naive Bayes\n",
    "\n",
    "[0, 1, 0, 1.......], target (1 - 7)\n",
    "\"\"\"\n",
    "#angerset.union(guiltset, joyset, shameset, sadness, disgustset)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "filehandler = open (\"joyUniq.pickle\", \"rb\")\n",
    "ju = pickle.load(filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "filehandler = open (\"shameUniq.pickle\", \"rb\")\n",
    "su = pickle.load(filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "filehandler = open (\"guiltUniq.pickle\", \"rb\")\n",
    "gu = pickle.load(filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "filehandler = open (\"negative.pickle\", \"rb\")\n",
    "neg = pickle.load(filehandler)\n",
    "filehandler.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "      Length   TTR  Fear  Anger  Guilt  Joy  Shame  Disgust  Sadness  \\\n0         10  0.30     0      1      0    1      0        0        1   \n1         21  0.43     1      1      1    0      1        1        0   \n2          6  0.67     1      1      1    1      1        1        1   \n3         49  0.41     1      1      1    1      1        1        1   \n4         26  0.46     0      0      0    0      1        1        0   \n...      ...   ...   ...    ...    ...  ...    ...      ...      ...   \n5321      62  0.32     1      1      1    1      1        1        1   \n5322      37  0.35     1      1      1    1      1        1        1   \n5323      13  0.62     1      1      1    1      1        1        1   \n5324      18  0.56     1      1      1    1      1        1        1   \n5325      17  0.41     1      1      1    1      1        1        1   \n\n      GuiltUnique  ShameUnique  JoyUnique  Negative  Target  \n0               0            0          0         0       4  \n1               0            0          0         1       1  \n2               0            0          0         0       4  \n3               0            0          0         1       1  \n4               0            1          0         1       5  \n...           ...          ...        ...       ...     ...  \n5321            0            0          0         1       7  \n5322            1            0          0         1       3  \n5323            0            0          0         0       1  \n5324            0            0          0         1       6  \n5325            0            0          0         0       5  \n\n[5326 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Length</th>\n      <th>TTR</th>\n      <th>Fear</th>\n      <th>Anger</th>\n      <th>Guilt</th>\n      <th>Joy</th>\n      <th>Shame</th>\n      <th>Disgust</th>\n      <th>Sadness</th>\n      <th>GuiltUnique</th>\n      <th>ShameUnique</th>\n      <th>JoyUnique</th>\n      <th>Negative</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>0.30</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21</td>\n      <td>0.43</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>0.67</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>49</td>\n      <td>0.41</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>26</td>\n      <td>0.46</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5321</th>\n      <td>62</td>\n      <td>0.32</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>5322</th>\n      <td>37</td>\n      <td>0.35</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5323</th>\n      <td>13</td>\n      <td>0.62</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5324</th>\n      <td>18</td>\n      <td>0.56</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>5325</th>\n      <td>17</td>\n      <td>0.41</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>5326 rows Ã— 14 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Feature Creation\n",
    "\"\"\"\n",
    "\n",
    "def featureCreation(input_df):\n",
    "    feature_df = pd.DataFrame()\n",
    "    input_df = input_df.dropna()\n",
    "    k = 0\n",
    "    res = []\n",
    "    for ind, rw in input_df.iterrows():\n",
    "        #print(row[1], row[0])\n",
    "        k += 1\n",
    "        #print(k)\n",
    "        temp = []\n",
    "        length = len(rw[1].split(\" \"))\n",
    "        temp.append(length)\n",
    "        row = [re.sub(\"[^A-Za-z]\", \"\", i) for i in rw[1].lower().split(\" \") if i not in stopwords]\n",
    "        temp.append(round(len(set(row))/length, 2))\n",
    "        # featureset100 = set([i[0] for i in fear100])\n",
    "        # print(featureset100)\n",
    "        if set(row).intersection(set([i[0] for i in fear100])):\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "\n",
    "        if set(row).intersection(set([i[0] for i in anger100])):\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "\n",
    "        if set(row).intersection(set([i[0] for i in guilt100])):\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "\n",
    "        if set(row).intersection(set([i[0] for i in joy100])):\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "\n",
    "        if set(row).intersection(set([i[0] for i in shame100])):\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "\n",
    "        if set(row).intersection(set([i[0] for i in disgust100])):\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "\n",
    "        if set(row).intersection(set([i[0] for i in sadness100])):\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "\n",
    "        if set(row).intersection(gu):\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "\n",
    "        if set(row).intersection(su):\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "\n",
    "        if set(row).intersection(ju):\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "\n",
    "        if set(row).intersection(neg):\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "        temp.append(int(rw[0]))\n",
    "        res.append(temp)\n",
    "\n",
    "    feature_df = pd.DataFrame(res, columns=[\"Length\", \"TTR\", \"Fear\", \"Anger\", \"Guilt\", \"Joy\", \"Shame\", \"Disgust\", \"Sadness\", \"GuiltUnique\", \"ShameUnique\", \"JoyUnique\", \"Negative\", \"Target\"])\n",
    "\n",
    "    return feature_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fedf = featureCreation(isear_train_df)\n",
    "fedf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "           Length       TTR      Fear     Anger     Guilt       Joy     Shame  \\\nTarget                                                                          \n1       23.645806  0.471744  0.909454  0.850866  0.828229  0.762983  0.832224   \n2       24.754617  0.464208  0.845646  0.918206  0.887863  0.825858  0.885224   \n3       23.627937  0.452833  0.851175  0.898172  0.912533  0.843342  0.908616   \n4       19.252252  0.471570  0.772201  0.844273  0.797941  0.927928  0.814672   \n5       22.132100  0.460132  0.792602  0.840159  0.853369  0.793923  0.895641   \n6       21.215324  0.497160  0.826948  0.857332  0.796565  0.801849  0.866579   \n7       20.396053  0.482224  0.830263  0.872368  0.859211  0.848684  0.852632   \n\n         Disgust   Sadness  GuiltUnique  ShameUnique  JoyUnique  Negative  \nTarget                                                                     \n1       0.801598  0.816245     0.000000     0.000000   0.000000  0.882823  \n2       0.878628  0.846966     0.203166     0.116095   0.096306  0.810026  \n3       0.873368  0.872063     0.526110     0.000000   0.000000  0.787206  \n4       0.779923  0.854569     0.000000     0.000000   0.516088  0.000000  \n5       0.828269  0.801849     0.000000     0.536328   0.000000  0.808454  \n6       0.912814  0.819022     0.000000     0.000000   0.000000  0.933950  \n7       0.851316  0.943421     0.081579     0.075000   0.121053  0.821053  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Length</th>\n      <th>TTR</th>\n      <th>Fear</th>\n      <th>Anger</th>\n      <th>Guilt</th>\n      <th>Joy</th>\n      <th>Shame</th>\n      <th>Disgust</th>\n      <th>Sadness</th>\n      <th>GuiltUnique</th>\n      <th>ShameUnique</th>\n      <th>JoyUnique</th>\n      <th>Negative</th>\n    </tr>\n    <tr>\n      <th>Target</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>23.645806</td>\n      <td>0.471744</td>\n      <td>0.909454</td>\n      <td>0.850866</td>\n      <td>0.828229</td>\n      <td>0.762983</td>\n      <td>0.832224</td>\n      <td>0.801598</td>\n      <td>0.816245</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.882823</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>24.754617</td>\n      <td>0.464208</td>\n      <td>0.845646</td>\n      <td>0.918206</td>\n      <td>0.887863</td>\n      <td>0.825858</td>\n      <td>0.885224</td>\n      <td>0.878628</td>\n      <td>0.846966</td>\n      <td>0.203166</td>\n      <td>0.116095</td>\n      <td>0.096306</td>\n      <td>0.810026</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>23.627937</td>\n      <td>0.452833</td>\n      <td>0.851175</td>\n      <td>0.898172</td>\n      <td>0.912533</td>\n      <td>0.843342</td>\n      <td>0.908616</td>\n      <td>0.873368</td>\n      <td>0.872063</td>\n      <td>0.526110</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.787206</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19.252252</td>\n      <td>0.471570</td>\n      <td>0.772201</td>\n      <td>0.844273</td>\n      <td>0.797941</td>\n      <td>0.927928</td>\n      <td>0.814672</td>\n      <td>0.779923</td>\n      <td>0.854569</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.516088</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>22.132100</td>\n      <td>0.460132</td>\n      <td>0.792602</td>\n      <td>0.840159</td>\n      <td>0.853369</td>\n      <td>0.793923</td>\n      <td>0.895641</td>\n      <td>0.828269</td>\n      <td>0.801849</td>\n      <td>0.000000</td>\n      <td>0.536328</td>\n      <td>0.000000</td>\n      <td>0.808454</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>21.215324</td>\n      <td>0.497160</td>\n      <td>0.826948</td>\n      <td>0.857332</td>\n      <td>0.796565</td>\n      <td>0.801849</td>\n      <td>0.866579</td>\n      <td>0.912814</td>\n      <td>0.819022</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.933950</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>20.396053</td>\n      <td>0.482224</td>\n      <td>0.830263</td>\n      <td>0.872368</td>\n      <td>0.859211</td>\n      <td>0.848684</td>\n      <td>0.852632</td>\n      <td>0.851316</td>\n      <td>0.943421</td>\n      <td>0.081579</td>\n      <td>0.075000</td>\n      <td>0.121053</td>\n      <td>0.821053</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {1: \"fear\", 2: \"anger\", 3: \"guilt\", 4: \"joy\", 5: \"shame\", 6: \"disgust\", 7: \"sadness\"}\n",
    "\"\"\"\n",
    "1. Length of sentence for Anger for highest.\n",
    "2. When the emotion is disgust, then there are more diverse words used.\n",
    "\"\"\"\n",
    "fedf.groupby(\"Target\").mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mp\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "data = fedf[[\"Length\", \"TTR\", \"Target\"]]\n",
    "data.corr()\n",
    "# plotting correlation heatmap\n",
    "dataplot = sb.heatmap(data.corr(), cmap=\"YlGnBu\", annot=True)\n",
    "\n",
    "# displaying heatmap\n",
    "mp.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "            Length          TTR       Target\ncount  5326.000000  5326.000000  5326.000000\nmean     22.135749     0.471384     4.003004\nstd      15.159316     0.107804     1.994450\nmin       1.000000     0.100000     1.000000\n25%      11.000000     0.400000     2.000000\n50%      19.000000     0.450000     4.000000\n75%      30.000000     0.520000     6.000000\nmax     187.000000     1.000000     7.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Length</th>\n      <th>TTR</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5326.000000</td>\n      <td>5326.000000</td>\n      <td>5326.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>22.135749</td>\n      <td>0.471384</td>\n      <td>4.003004</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>15.159316</td>\n      <td>0.107804</td>\n      <td>1.994450</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.100000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>11.000000</td>\n      <td>0.400000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>19.000000</td>\n      <td>0.450000</td>\n      <td>4.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>30.000000</td>\n      <td>0.520000</td>\n      <td>6.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>187.000000</td>\n      <td>1.000000</td>\n      <td>7.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "bins = [1, 22, 187]\n",
    "labels = [0, 1]\n",
    "fedf[\"length_binned\"] = pd.cut(fedf['Length'], bins,labels=labels)\n",
    "\n",
    "bins2 = [0.1, 0.47, 1]\n",
    "labels2 = [0, 1]\n",
    "fedf[\"ttr_binned\"] = pd.cut(fedf['TTR'], bins2,labels=labels2)\n",
    "fedf[\"Emotion-Target\"] = fedf[\"Target\"]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "fedf = fedf.fillna(0)\n",
    "fedf.drop(columns=[\"Length\", \"TTR\", \"Target\"]).to_excel(\"inputData.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "      Length   TTR  Fear  Anger  Guilt  Joy  Shame  Disgust  Sadness  \\\n0         10  0.30     0      1      0    1      0        0        1   \n1         21  0.43     1      1      1    0      1        1        0   \n2          6  0.67     1      1      1    1      1        1        1   \n3         49  0.41     1      1      1    1      1        1        1   \n4         26  0.46     0      0      0    0      1        1        0   \n...      ...   ...   ...    ...    ...  ...    ...      ...      ...   \n5321      62  0.32     1      1      1    1      1        1        1   \n5322      37  0.35     1      1      1    1      1        1        1   \n5323      13  0.62     1      1      1    1      1        1        1   \n5324      18  0.56     1      1      1    1      1        1        1   \n5325      17  0.41     1      1      1    1      1        1        1   \n\n      GuiltUnique  ShameUnique  JoyUnique  Negative  Target length_binned  \\\n0               0            0          0         0       4             0   \n1               0            0          0         1       1             0   \n2               0            0          0         0       4             0   \n3               0            0          0         1       1             1   \n4               0            1          0         1       5             1   \n...           ...          ...        ...       ...     ...           ...   \n5321            0            0          0         1       7             1   \n5322            1            0          0         1       3             1   \n5323            0            0          0         0       1             0   \n5324            0            0          0         1       6             0   \n5325            0            0          0         0       5             0   \n\n     ttr_binned  Emotion-Target  \n0             0               4  \n1             0               1  \n2             1               4  \n3             0               1  \n4             0               5  \n...         ...             ...  \n5321          0               7  \n5322          0               3  \n5323          1               1  \n5324          1               6  \n5325          0               5  \n\n[5326 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Length</th>\n      <th>TTR</th>\n      <th>Fear</th>\n      <th>Anger</th>\n      <th>Guilt</th>\n      <th>Joy</th>\n      <th>Shame</th>\n      <th>Disgust</th>\n      <th>Sadness</th>\n      <th>GuiltUnique</th>\n      <th>ShameUnique</th>\n      <th>JoyUnique</th>\n      <th>Negative</th>\n      <th>Target</th>\n      <th>length_binned</th>\n      <th>ttr_binned</th>\n      <th>Emotion-Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>0.30</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21</td>\n      <td>0.43</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>0.67</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>49</td>\n      <td>0.41</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>26</td>\n      <td>0.46</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5321</th>\n      <td>62</td>\n      <td>0.32</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>5322</th>\n      <td>37</td>\n      <td>0.35</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5323</th>\n      <td>13</td>\n      <td>0.62</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5324</th>\n      <td>18</td>\n      <td>0.56</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>5325</th>\n      <td>17</td>\n      <td>0.41</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>5326 rows Ã— 17 columns</p>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fedf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self, df_train, df_test, no_labels):\n",
    "        self.no_labels = no_labels\n",
    "        self.N = df_train.shape[0]\n",
    "        self.df_train = df_train\n",
    "        self.df_test = df_test\n",
    "        self.featureSet = [\"Fear\", \"Anger\", \"Guilt\", \"Joy\", \"Shame\", \"Disgust\", \"Sadness\", \"GuiltUnique\",\n",
    "                           \"ShameUnique\", \"JoyUnique\", \"Negative\", \"length_binned\", \"ttr_binned\"]\n",
    "\n",
    "        self.map_data_by_class = {}\n",
    "        self.class_prob = [0] * self.no_labels\n",
    "        self.evidence_prob = [[0] * len(self.featureSet) for i in range(self.no_labels)]\n",
    "       # self.evidence_prob_false = [[0] * len(self.featureSet) for i in range(self.no_labels)]\n",
    "        self.pred_prob = [[0] * self.no_labels for i in range(df_test.shape[0])]\n",
    "        # shape of pred_prob = 5326(shape of test set) * 7\n",
    "\n",
    "\n",
    "    def naive_bayes_fit(self):\n",
    "\n",
    "        # split data by class\n",
    "        for i in range(1, self.no_labels + 1):\n",
    "            self.map_data_by_class[i] = self.df_train[self.df_train['Emotion-Target'] == i]\n",
    "\n",
    "            # compute prior probability of each class P(y=i)\n",
    "            self.class_prob[i - 1] = self.map_data_by_class.get(i).shape[0] / self.N\n",
    "\n",
    "        # compute likelihood of evidence in each class, i=emotion, j=feature\n",
    "        for i in range(1, self.no_labels + 1):\n",
    "            for j, feature in enumerate(self.featureSet):\n",
    "                cdf = self.map_data_by_class.get(i)  # class i\n",
    "                self.evidence_prob[i - 1][j] = cdf[cdf[feature] == 1].shape[0] / cdf.shape[0]  # prob. that the feature is 1 in class i\n",
    "\n",
    "\n",
    "    def predict(self, instance):\n",
    "        pred_proba = []\n",
    "        for i in range(self.no_labels):\n",
    "            nominator = 0\n",
    "            for j, value in enumerate(instance):\n",
    "                if value == 1:\n",
    "                    nominator = nominator + self.evidence_prob[i][j]\n",
    "            p_tc = nominator / self.class_prob[i]\n",
    "            pred_proba.append(np.log(p_tc) + np.log(self.class_prob[i]))\n",
    "            #pred_proba.append(p_tc)\n",
    "            pred_class = np.argmax(pred_proba)\n",
    "        return pred_class\n",
    "\n",
    "    def naive_bayes_predict(self):\n",
    "        pred = []\n",
    "        for ind, row in self.df_test.iterrows():\n",
    "            pred.append(self.predict(row))\n",
    "        self.df_test[\"Target-Predicted\"] = pred\n",
    "        return self.df_test\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "input_df = pd.read_excel(\"./inputData.xlsx\").drop(columns=[\"Unnamed: 0\"])\n",
    "#input_df = input_df[input_df[\"Emotion-Target\"].isin([1, 4])]\n",
    "modelObj = NaiveBayes(df_train=input_df, df_test=input_df.drop(columns=[\"Emotion-Target\"]), no_labels=7)\n",
    "modelObj.naive_bayes_fit()\n",
    "pred = modelObj.naive_bayes_predict()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  14.27\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i, j in zip(input_df[\"Emotion-Target\"], pred[\"Target-Predicted\"]):\n",
    "    if i == j:\n",
    "        c += 1\n",
    "print(\"Accuracy = \", round(c/input_df.shape[0] * 100, 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}